{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "max_cell_id": 35,
    "colab": {
      "name": "hw01_part2_tony_upd.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 1,
        "id": "kr9vAeEQlRVG"
      },
      "source": [
        "# Домашнее задание 2. Классификация изображений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 3,
        "id": "BxX49gLclRVJ"
      },
      "source": [
        "В этом задании потребуется обучить классификатор изображений. Будем работать с датасетом, название которого раскрывать не будем. Можете посмотреть самостоятельно на картинки, которые в есть датасете. В нём 200 классов и около 5 тысяч картинок на каждый класс. Классы пронумерованы, как нетрудно догадаться, от 0 до 199. Скачать датасет можно вот [тут](https://yadi.sk/d/BNR41Vu3y0c7qA).\n",
        "\n",
        "Структура датасета простая -- есть директории train/ и val/, в которых лежат обучающие и валидационные данные. В train/ и val/ лежат директориии, соответствующие классам изображений, в которых лежат, собственно, сами изображения.\n",
        " \n",
        "__Задание__. Необходимо выполнить любое из двух заданий\n",
        "\n",
        "1) Добейтесь accuracy **на валидации не менее 0.44**. В этом задании **запрещено** пользоваться предобученными моделями и ресайзом картинок. \n",
        "\n",
        "2) Добейтесь accuracy **на валидации не менее 0.84**. В этом задании делать ресайз и использовать претрейн можно. \n",
        "\n",
        "Напишите краткий отчёт о проделанных экспериментах. Что сработало и что не сработало? Почему вы решили, сделать так, а не иначе? Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете. \n",
        "\n",
        "Ваш код обязательно должен проходить все `assert`'ы ниже.\n",
        "\n",
        "Необходимо написать функции `train_one_epoch`, `train` и `predict` по шаблонам ниже (во многом повторяют примеры с семинаров).Обратите особое внимание на функцию `predict`: она должна возвращать список лоссов по всем объектам даталоадера, список предсказанных классов для каждого объекта из даталоалера и список настоящих классов для каждого объекта в даталоадере (и именно в таком порядке).\n",
        "\n",
        "__Использовать внешние данные для обучения строго запрещено в обоих заданиях. Также запрещено обучаться на валидационной выборке__.\n",
        "\n",
        "\n",
        "__Критерии оценки__: Оценка вычисляется по простой формуле: `min(10, 10 * Ваша accuracy / 0.44)` для первого задания и `min(10, 10 * (Ваша accuracy - 0.5) / 0.34)` для второго. Оценка округляется до десятых по арифметическим правилам. Если вы выполнили оба задания, то берется максимум из двух оценок.\n",
        "\n",
        "__Бонус__. Вы получаете 5 бонусных баллов если справляетесь с обоими заданиями на 10 баллов (итого 15 баллов). В противном случае выставляется максимальная из двух оценок и ваш бонус равен нулю.\n",
        "\n",
        "__Советы и указания__:\n",
        " - Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят. Но не забывайте, что нужно быть готовым за скатанный код отвечать :)\n",
        " - Используйте аугментации. Для этого пользуйтесь модулем `torchvision.transforms` или библиотекой [albumentations](https://github.com/albumentations-team/albumentations)\n",
        " - Можно обучать с нуля или файнтюнить (в зависимости от задания) модели из `torchvision`.\n",
        " - Рекомендуем написать вам сначала класс-датасет (или воспользоваться классом `ImageFolder`), который возвращает картинки и соответствующие им классы, а затем функции для трейна по шаблонам ниже. Однако делать это мы не заставляем. Если вам так неудобно, то можете писать код в удобном стиле. Однако учтите, что чрезмерное изменение нижеперечисленных шаблонов увеличит количество вопросов к вашему коду и повысит вероятность вызова на защиту :)\n",
        " - Валидируйте. Трекайте ошибки как можно раньше, чтобы не тратить время впустую.\n",
        " - Чтобы быстро отладить код, пробуйте обучаться на маленькой части датасета (скажем, 5-10 картинок просто чтобы убедиться что код запускается). Когда вы поняли, что смогли всё отдебажить, переходите обучению по всему датасету\n",
        " - На каждый запуск делайте ровно одно изменение в модели/аугментации/оптимайзере, чтобы понять, что и как влияет на результат.\n",
        " - Фиксируйте random seed.\n",
        " - Начинайте с простых моделей и постепенно переходите к сложным. Обучение лёгких моделей экономит много времени.\n",
        " - Ставьте расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать.\n",
        " - Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 15 минут обучения.\n",
        " \n",
        "Good luck & have fun! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 4,
        "id": "LKcSNj4tlRVK"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# You may add any imports you need"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qtHU_QTqw-p",
        "outputId": "d7a5685d-a6d2-42c4-c32f-d0f5fb5d7bae"
      },
      "source": [
        "!wget https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-03 17:35:39--  https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/33l8lp62rmvtx40/dataset.zip [following]\n",
            "--2021-11-03 17:35:39--  https://www.dropbox.com/s/raw/33l8lp62rmvtx40/dataset.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca53a414c59e959d5607b15de70.dl.dropboxusercontent.com/cd/0/inline/BZR7mRD5sFDsXbIFzMMQOh5eohpL0oHdR_Uv-GpUn9FlFkoLTjI8-XEOUnnMeQH_EpVC1VAvt350K3wmhd3tKu_NOosq9PGySNRQRorKBZcTjphqkXkO2Drn9OHBiPSUjmdRzgXoTTobP2AQoCUE-Pbz/file# [following]\n",
            "--2021-11-03 17:35:39--  https://uca53a414c59e959d5607b15de70.dl.dropboxusercontent.com/cd/0/inline/BZR7mRD5sFDsXbIFzMMQOh5eohpL0oHdR_Uv-GpUn9FlFkoLTjI8-XEOUnnMeQH_EpVC1VAvt350K3wmhd3tKu_NOosq9PGySNRQRorKBZcTjphqkXkO2Drn9OHBiPSUjmdRzgXoTTobP2AQoCUE-Pbz/file\n",
            "Resolving uca53a414c59e959d5607b15de70.dl.dropboxusercontent.com (uca53a414c59e959d5607b15de70.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uca53a414c59e959d5607b15de70.dl.dropboxusercontent.com (uca53a414c59e959d5607b15de70.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BZQcEVmCRWHel-oWx2YdtBa4TUsbNsGvn8LIusAfmzw-mIxy5qE2Jvhn01n05bHfEQF2yIRXzi80EmIiacA3fLr-NR60EqQdfnR2HS5VIJH7BQl2VxZ9SmVqO7oK_-BSErqzQGOV5KkfMUNmD8VQgGC9eD2d7YTS4Hyhw7NdLiTj2PkMF0uNcituGzEfkf7ujiNTz1H2FRct7s1a48wEowRJRDaL1k_SGHvwNgP-HpfRR7sLJ9vmnISlo7l2IdQHuLSRUpsW8KiUX3OJYZ6V19_XGhsBTevgCg15FJNsksyWCWsp-0CCBM88ShqgYpgfhvYh84SLvfs-8MSDC3xocfJokf2iABOlFVYTMtZ3-8mOUuxhCSCx-NIgH8ak1z4GvBw/file [following]\n",
            "--2021-11-03 17:35:39--  https://uca53a414c59e959d5607b15de70.dl.dropboxusercontent.com/cd/0/inline2/BZQcEVmCRWHel-oWx2YdtBa4TUsbNsGvn8LIusAfmzw-mIxy5qE2Jvhn01n05bHfEQF2yIRXzi80EmIiacA3fLr-NR60EqQdfnR2HS5VIJH7BQl2VxZ9SmVqO7oK_-BSErqzQGOV5KkfMUNmD8VQgGC9eD2d7YTS4Hyhw7NdLiTj2PkMF0uNcituGzEfkf7ujiNTz1H2FRct7s1a48wEowRJRDaL1k_SGHvwNgP-HpfRR7sLJ9vmnISlo7l2IdQHuLSRUpsW8KiUX3OJYZ6V19_XGhsBTevgCg15FJNsksyWCWsp-0CCBM88ShqgYpgfhvYh84SLvfs-8MSDC3xocfJokf2iABOlFVYTMtZ3-8mOUuxhCSCx-NIgH8ak1z4GvBw/file\n",
            "Reusing existing connection to uca53a414c59e959d5607b15de70.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 220318689 (210M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 210.11M  60.0MB/s    in 3.5s    \n",
            "\n",
            "2021-11-03 17:35:44 (59.4 MB/s) - ‘dataset.zip’ saved [220318689/220318689]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb4fwSRus_dk"
      },
      "source": [
        "!unzip -o \"dataset.zip\" -d \"./\" > /dev/null\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI8pq7AQtL1P",
        "outputId": "7a0b970a-c8de-4a51-b216-4ead8bf0223e"
      },
      "source": [
        "!ls dataset/dataset/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RytEDW0ylRVN"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 5,
        "id": "QEdDQtHdlRVO"
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (1, 1, 1)),\n",
        "]\n",
        ")\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (1, 1, 1)),\n",
        "]\n",
        ")\n",
        "\n",
        "train_dataset = ImageFolder(\"./dataset/dataset/train\", transform=train_transform)\n",
        "val_dataset = ImageFolder(\"./dataset/dataset/val\", transform=val_transform)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 6,
        "id": "mrg4Yj0VlRVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231198c3-a1ed-4d47-99aa-2f68992c5494"
      },
      "source": [
        "# Just very simple sanity checks\n",
        "assert isinstance(train_dataset[0], tuple)\n",
        "assert len(train_dataset[0]) == 2\n",
        "assert isinstance(train_dataset[1][1], int)\n",
        "print(\"tests passed\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tests passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RlSlmyjlRVP"
      },
      "source": [
        "### Вспомогательные функции, реализация модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 7,
        "id": "yYG2-Cq8lRVQ"
      },
      "source": [
        "# Код с 6-го семинара\n",
        "def train_one_epoch(model, data_loader, criterion, optimizer, device=\"cuda:0\"):\n",
        "    model = model.to(device).train()\n",
        "    total_loss = 0\n",
        "    losses = np.array([])\n",
        "    total_predictions = np.array([])#.reshape((0, ))\n",
        "    total_labels = np.array([])#.reshape((0, ))\n",
        "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
        "        for images, labels in data_loader:\n",
        "            # Move Batch to device\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predicted = model(images)\n",
        "            elementwise_loss = criterion(predicted, labels)\n",
        "            loss = torch.mean(elementwise_loss)\n",
        "            \n",
        "            # Update weights\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            loss = loss.cpu().detach().numpy()\n",
        "            elementwise_loss = elementwise_loss.cpu().detach().numpy()\n",
        "            # Update descirption for tqdm\n",
        "            accuracy = (predicted.argmax(1) == labels).cpu().float().mean().numpy()\n",
        "            prbar.set_description(\n",
        "                f\"Loss: {round(loss.item(), 4)} \"\n",
        "                f\"Accuracy: {round(accuracy.item(), 4)}\"\n",
        "            )\n",
        "            prbar.update(1)\n",
        "\n",
        "            losses = np.append(losses, elementwise_loss)\n",
        "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
        "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
        "    \n",
        "    return losses, total_predictions, total_labels\n",
        "\n",
        "\n",
        "# Код с 5-го семинара\n",
        "def predict(model, data_loader, criterion, device=\"cuda:0\"):\n",
        "    model = model.eval()\n",
        "    losses = np.array([])\n",
        "    total_predictions = np.array([])\n",
        "    total_labels = np.array([])\n",
        "    with torch.no_grad():\n",
        "        with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
        "            for images, labels in data_loader:\n",
        "                # Move Batch to device\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                predicted = model(images)\n",
        "                elementwise_loss = criterion(predicted, labels)\n",
        "\n",
        "                # Move data back to cpu\n",
        "                elementwise_loss = elementwise_loss.cpu()\n",
        "                predicted_classes = predicted.argmax(1).cpu()\n",
        "\n",
        "                # Compute metrics\n",
        "                batch_loss = torch.mean(elementwise_loss).numpy()\n",
        "                batch_accuracy = torch.mean((predicted_classes == labels.cpu()).float()).numpy()\n",
        "                prbar.set_description(\n",
        "                    f\"Loss: {round(batch_loss.item(), 4)} \"\n",
        "                    f\"Accuracy: {round(batch_accuracy.item(), 4)}\"\n",
        "                )\n",
        "                prbar.update(1)\n",
        "\n",
        "                losses = np.append(losses, elementwise_loss.numpy())\n",
        "                total_predictions = np.append(total_predictions, predicted_classes.numpy())\n",
        "                total_labels = np.append(total_labels, labels.cpu().numpy())\n",
        "\n",
        "    return losses, total_predictions, total_labels\n",
        "\n",
        "\n",
        "# частично с помощью https://matplotlib.org/devdocs/gallery/subplots_axes_and_figures/subplots_demo.html\n",
        "def plot_metrics(train, val):\n",
        "    clear_output(True)\n",
        "    fig, axs = plt.subplots(2, figsize=(13, 14))\n",
        "    fig.suptitle('Learning progress')\n",
        "\n",
        "    epoch = len(train[metric_name])\n",
        "    for i, metric_name in enumerate(['loss', 'accuracy']):\n",
        "        train_metric = train[metric_name]\n",
        "        val_metric = val[metric_name]\n",
        "        axs[i].set_title(metric_name)\n",
        "        axs[i].set(xlabel='epoch', ylabel=metric_name)\n",
        "        axs[i].plot(np.arange(1, epoch + 1), train_metric, label='train', color='r')\n",
        "        axs[i].plot(np.arange(1, epoch + 1), val_metric, label='validation', color='b')\n",
        "        axs[i].scatter(epoch, train_metric[-1], label='Last {}={:.2f} on train'.format(metric_name, train_metric[-1]))\n",
        "        axs[i].scatter(epoch, val_metric[-1], label='Last {}={:.2f} on validation'.format(metric_name, val_metric[-1]))\n",
        "\n",
        "\n",
        "# Частично мой код из первого домашнего задания\n",
        "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n",
        "    model.to(device)\n",
        "    train_metrics = {\n",
        "        'loss' : [],\n",
        "        'accuracy' : []\n",
        "    }\n",
        "    val_metrics = {\n",
        "        'loss' : [],\n",
        "        'accuracy' : []\n",
        "    }\n",
        "    for epoch in range(n_epochs):\n",
        "        losses, predicted_classes, true_classes = train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
        "        train_metrics['loss'].append(losses.mean())\n",
        "        train_metrics['acc'].append((predicted_classes == true_classes).float().mean())\n",
        "\n",
        "        losses, predicted_classes, true_classes = predict(model, val_dataloader, criterion, device)\n",
        "        val_metrics['loss'].append(losses.mean())\n",
        "        val_metrics['acc'].append((predicted_classes == true_classes).float().mean())\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "        plot_metrics(train_metrics, val_metrics)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxR3gfcilRVW"
      },
      "source": [
        "### Обучение модели, запуски экспериментов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 8,
        "scrolled": true,
        "id": "JXFJ6oS8lRVX"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 8, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(8, 16, 3),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(3136, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 200),\n",
        ").to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# scheduler = ExponentialLR(optimizer, gamma=0.95)\n",
        "scheduler = None\n",
        "n_epochs = 10\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwkGXGUws8J5",
        "outputId": "f12a37bd-21c4-44e6-e88b-0cf5bdccf6fb"
      },
      "source": [
        "model(torch.zeros((1, 3, 64, 64)).to(device)).shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 9,
        "id": "CesoOl6BlRVY"
      },
      "source": [
        "Простой тест на проверку правильности написанного кода"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 10,
        "id": "B_LB2jn6lRVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76dae2b-df5b-47d6-c831-b73be794e1d0"
      },
      "source": [
        "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "assert len(predicted_labels) == len(val_dataset)\n",
        "accuracy = accuracy_score(predicted_labels, true_labels)\n",
        "print(\"tests passed\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 5.3103 Accuracy: 0.0: 100%|██████████| 40/40 [00:07<00:00,  5.34it/s]\n",
            "tests passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 11,
        "id": "tS-LLiXUlRVY"
      },
      "source": [
        "Запустить обучение можно в ячейке ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 12,
        "id": "ECIzZ_RYlRVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762c0adb-d106-42b1-cf2d-f747918ce6e4"
      },
      "source": [
        "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.481 Accuracy: 0.0781:  43%|████▎     | 168/391 [00:39<00:51,  4.30it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVW8_EXlRVZ"
      },
      "source": [
        "### Проверка полученной accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 13,
        "id": "FmR-elhJlRVZ"
      },
      "source": [
        "После всех экспериментов которые вы проделали, выберите лучшую из своих моделей, реализуйте и запустите функцию `evaluate`. Эта функция должна брать на вход модель и даталоадер с валидационными данными и возврашать accuracy, посчитанную на этом датасете."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 14,
        "id": "3TGH0EFalRVb"
      },
      "source": [
        "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "assert len(predicted_labels) == len(val_dataset)\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(\"Оценка за это задание составит {} баллов\".format(min(5, 5 * accuracy / 0.44)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 15,
        "id": "pT8vfPSolRVb"
      },
      "source": [
        "### Отчёт об экспериментах \n",
        "\n",
        "текст писать тут"
      ]
    }
  ]
}