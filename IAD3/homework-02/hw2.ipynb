{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "max_cell_id": 35,
    "colab": {
      "name": "hw01_part2_tony_upd.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 1,
        "id": "kr9vAeEQlRVG"
      },
      "source": [
        "# Домашнее задание 2. Классификация изображений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 3,
        "id": "BxX49gLclRVJ"
      },
      "source": [
        "В этом задании потребуется обучить классификатор изображений. Будем работать с датасетом, название которого раскрывать не будем. Можете посмотреть самостоятельно на картинки, которые в есть датасете. В нём 200 классов и около 5 тысяч картинок на каждый класс. Классы пронумерованы, как нетрудно догадаться, от 0 до 199. Скачать датасет можно вот [тут](https://yadi.sk/d/BNR41Vu3y0c7qA).\n",
        "\n",
        "Структура датасета простая -- есть директории train/ и val/, в которых лежат обучающие и валидационные данные. В train/ и val/ лежат директориии, соответствующие классам изображений, в которых лежат, собственно, сами изображения.\n",
        " \n",
        "__Задание__. Необходимо выполнить любое из двух заданий\n",
        "\n",
        "1) Добейтесь accuracy **на валидации не менее 0.44**. В этом задании **запрещено** пользоваться предобученными моделями и ресайзом картинок. \n",
        "\n",
        "2) Добейтесь accuracy **на валидации не менее 0.84**. В этом задании делать ресайз и использовать претрейн можно. \n",
        "\n",
        "Напишите краткий отчёт о проделанных экспериментах. Что сработало и что не сработало? Почему вы решили, сделать так, а не иначе? Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете. \n",
        "\n",
        "Ваш код обязательно должен проходить все `assert`'ы ниже.\n",
        "\n",
        "Необходимо написать функции `train_one_epoch`, `train` и `predict` по шаблонам ниже (во многом повторяют примеры с семинаров).Обратите особое внимание на функцию `predict`: она должна возвращать список лоссов по всем объектам даталоадера, список предсказанных классов для каждого объекта из даталоалера и список настоящих классов для каждого объекта в даталоадере (и именно в таком порядке).\n",
        "\n",
        "__Использовать внешние данные для обучения строго запрещено в обоих заданиях. Также запрещено обучаться на валидационной выборке__.\n",
        "\n",
        "\n",
        "__Критерии оценки__: Оценка вычисляется по простой формуле: `min(10, 10 * Ваша accuracy / 0.44)` для первого задания и `min(10, 10 * (Ваша accuracy - 0.5) / 0.34)` для второго. Оценка округляется до десятых по арифметическим правилам. Если вы выполнили оба задания, то берется максимум из двух оценок.\n",
        "\n",
        "__Бонус__. Вы получаете 5 бонусных баллов если справляетесь с обоими заданиями на 10 баллов (итого 15 баллов). В противном случае выставляется максимальная из двух оценок и ваш бонус равен нулю.\n",
        "\n",
        "__Советы и указания__:\n",
        " - Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят. Но не забывайте, что нужно быть готовым за скатанный код отвечать :)\n",
        " - Используйте аугментации. Для этого пользуйтесь модулем `torchvision.transforms` или библиотекой [albumentations](https://github.com/albumentations-team/albumentations)\n",
        " - Можно обучать с нуля или файнтюнить (в зависимости от задания) модели из `torchvision`.\n",
        " - Рекомендуем написать вам сначала класс-датасет (или воспользоваться классом `ImageFolder`), который возвращает картинки и соответствующие им классы, а затем функции для трейна по шаблонам ниже. Однако делать это мы не заставляем. Если вам так неудобно, то можете писать код в удобном стиле. Однако учтите, что чрезмерное изменение нижеперечисленных шаблонов увеличит количество вопросов к вашему коду и повысит вероятность вызова на защиту :)\n",
        " - Валидируйте. Трекайте ошибки как можно раньше, чтобы не тратить время впустую.\n",
        " - Чтобы быстро отладить код, пробуйте обучаться на маленькой части датасета (скажем, 5-10 картинок просто чтобы убедиться что код запускается). Когда вы поняли, что смогли всё отдебажить, переходите обучению по всему датасету\n",
        " - На каждый запуск делайте ровно одно изменение в модели/аугментации/оптимайзере, чтобы понять, что и как влияет на результат.\n",
        " - Фиксируйте random seed.\n",
        " - Начинайте с простых моделей и постепенно переходите к сложным. Обучение лёгких моделей экономит много времени.\n",
        " - Ставьте расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать.\n",
        " - Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 15 минут обучения.\n",
        " \n",
        "Good luck & have fun! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 4,
        "id": "LKcSNj4tlRVK"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "import tqdm\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# You may add any imports you need"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qtHU_QTqw-p",
        "outputId": "5427ccf6-389e-4332-b019-dc8df50ee0e7"
      },
      "source": [
        "!wget https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-01 18:12:25--  https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/33l8lp62rmvtx40/dataset.zip [following]\n",
            "--2021-11-01 18:12:25--  https://www.dropbox.com/s/raw/33l8lp62rmvtx40/dataset.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc75cf834cc1006038a51b46dfd5.dl.dropboxusercontent.com/cd/0/inline/BZKStt0qro-4csZjyueOgPyouxDWkJe0svrkTskd0pJDD7tf4Fg3XzO5oa3U3e6aYfNTTSEtKTla6qU5hsbK5nR-RAGOaNGo8oFlSU3Lel9qWX9gO59urUgj9OtXqA9ZaJI744ufkm9RfRN5KtM1Fjmm/file# [following]\n",
            "--2021-11-01 18:12:25--  https://uc75cf834cc1006038a51b46dfd5.dl.dropboxusercontent.com/cd/0/inline/BZKStt0qro-4csZjyueOgPyouxDWkJe0svrkTskd0pJDD7tf4Fg3XzO5oa3U3e6aYfNTTSEtKTla6qU5hsbK5nR-RAGOaNGo8oFlSU3Lel9qWX9gO59urUgj9OtXqA9ZaJI744ufkm9RfRN5KtM1Fjmm/file\n",
            "Resolving uc75cf834cc1006038a51b46dfd5.dl.dropboxusercontent.com (uc75cf834cc1006038a51b46dfd5.dl.dropboxusercontent.com)... 162.125.7.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc75cf834cc1006038a51b46dfd5.dl.dropboxusercontent.com (uc75cf834cc1006038a51b46dfd5.dl.dropboxusercontent.com)|162.125.7.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BZJhARQXKXc4BBYxbMwBMvhbQ8JVHpAAwjKeWNXWJUbyUD1MJQsWf59i6jwdglotgNcLP-3_YZsLu1aqbeHKm3o4JFOVzNyJRnD-oeIwFrs5OBSNF7_Jb-TR_wj3wHSXg5NgvHIKJ2ce1YDLE0u7TOasQ7GN7gBLPHsopRTFMVnjNgGRQtVPg1OkwsiOOmUgJPOjRzG-vjGXUIhxauKn84SFeyqnrDVOlugf3wG0IRo6BE8oii06mBZq9-jWD1GC1z08cU-2XDTE9C1jWnpDOZ3pC-IxyRSrYQe_ReliQQV_v_gLyXvPqKwCwaiOwDhliXxGJxB7To0kShsEuMKM0cLFQsfsaln0nC7u7upfrmHLRCe4AJ1BZLk-8P3uvgqtgcY/file [following]\n",
            "--2021-11-01 18:12:25--  https://uc75cf834cc1006038a51b46dfd5.dl.dropboxusercontent.com/cd/0/inline2/BZJhARQXKXc4BBYxbMwBMvhbQ8JVHpAAwjKeWNXWJUbyUD1MJQsWf59i6jwdglotgNcLP-3_YZsLu1aqbeHKm3o4JFOVzNyJRnD-oeIwFrs5OBSNF7_Jb-TR_wj3wHSXg5NgvHIKJ2ce1YDLE0u7TOasQ7GN7gBLPHsopRTFMVnjNgGRQtVPg1OkwsiOOmUgJPOjRzG-vjGXUIhxauKn84SFeyqnrDVOlugf3wG0IRo6BE8oii06mBZq9-jWD1GC1z08cU-2XDTE9C1jWnpDOZ3pC-IxyRSrYQe_ReliQQV_v_gLyXvPqKwCwaiOwDhliXxGJxB7To0kShsEuMKM0cLFQsfsaln0nC7u7upfrmHLRCe4AJ1BZLk-8P3uvgqtgcY/file\n",
            "Reusing existing connection to uc75cf834cc1006038a51b46dfd5.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 220318689 (210M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 210.11M  45.1MB/s    in 5.0s    \n",
            "\n",
            "2021-11-01 18:12:31 (41.7 MB/s) - ‘dataset.zip’ saved [220318689/220318689]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb4fwSRus_dk"
      },
      "source": [
        "!unzip -o \"dataset.zip\" -d \"./\" > /dev/null\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI8pq7AQtL1P",
        "outputId": "b511a7fa-2262-449d-e2fb-f47ed4d30f25"
      },
      "source": [
        "!ls dataset/dataset/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RytEDW0ylRVN"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 5,
        "id": "QEdDQtHdlRVO"
      },
      "source": [
        "train_transform = None\n",
        "val_transform = None\n",
        "\n",
        "train_dataset = ImageFolder(\"./dataset/dataset/train\", transform=train_transform)\n",
        "val_dataset = ImageFolder(\"./dataset/dataset/val\", transform=val_transform)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=False)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 6,
        "id": "mrg4Yj0VlRVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b36d086-cbf0-49e2-bcb4-16d92d16f279"
      },
      "source": [
        "# Just very simple sanity checks\n",
        "assert isinstance(train_dataset[0], tuple)\n",
        "assert len(train_dataset[0]) == 2\n",
        "assert isinstance(train_dataset[1][1], int)\n",
        "print(\"tests passed\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tests passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RlSlmyjlRVP"
      },
      "source": [
        "### Вспомогательные функции, реализация модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 7,
        "id": "yYG2-Cq8lRVQ"
      },
      "source": [
        "# Код с 6-го семинара\n",
        "def train_one_epoch(model, data_loader, criterion, optimizer, device=\"cuda:0\"):\n",
        "    model = model.to(device).train()\n",
        "    total_loss = 0\n",
        "    num_batches = len(data_loader)\n",
        "    losses = np.array([])\n",
        "    total_predictions = np.array([])#.reshape((0, ))\n",
        "    total_labels = np.array([])#.reshape((0, ))\n",
        "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
        "        for images, labels in data_loader:\n",
        "            # Move Batch to device\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predicted = model(images)\n",
        "            elementwise_loss = criterion(predicted, labels)\n",
        "            loss = torch.mean(elementwise_loss)\n",
        "            \n",
        "            # Update weights\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            loss = loss.cpu().detach().numpy()\n",
        "            elementwise_loss = elementwise_loss.cpu().detach().numpy()\n",
        "            # Update descirption for tqdm\n",
        "            accuracy = (predicted.argmax(1) == labels).cpu().float().mean().numpy()\n",
        "            prbar.set_description(\n",
        "                f\"Loss: {round(loss, 4)} \"\n",
        "                f\"Accuracy: {round(accuracy * 100, 4)}\"\n",
        "            )\n",
        "            prbar.update(1)\n",
        "\n",
        "            losses = np.append(losses, elementwise_loss)\n",
        "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
        "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
        "            num_batches += 1\n",
        "            all_losses.append(loss)\n",
        "    \n",
        "    return losses, predicted_classes, true_classes\n",
        "\n",
        "\n",
        "# Код с 5-го семинара\n",
        "def predict(model, dataloder, criterion, device=\"cuda:0\"):\n",
        "    model = model.eval()\n",
        "    num_batches = len(data_loader)\n",
        "    losses = np.array([])\n",
        "    total_predictions = np.array([])\n",
        "    total_labels = np.array([])\n",
        "    with tqdm(total=num_batches, file=sys.stdout) as prbar:\n",
        "        for images, labels in data_loader:\n",
        "            # Move Batch to device\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predicted = model(images)\n",
        "            elementwise_loss = criterion(predicted, labels)\n",
        "\n",
        "            # Move data back to cpu\n",
        "            elementwise_loss = elementwise_loss.cpu()\n",
        "            predicted_classes = predicted.argmax(1).cpu()\n",
        "\n",
        "            # Compute metrics\n",
        "            batch_loss = torch.mean(elementwise_loss).numpy()\n",
        "            batch_accuracy = torch.mean((predicted_classes == labels.cpu()).float()).numpy()\n",
        "            prbar.set_description(\n",
        "                f\"Loss: {round(batch_loss, 4)} \"\n",
        "                f\"Accuracy: {round(batch_accuracy * 100, 4)}\"\n",
        "            )\n",
        "            prbar.update(1)\n",
        "\n",
        "            losses = np.append(losses, elementwise_loss.numpy())\n",
        "            total_predictions = np.append(total_predictions, predicted_classes.numpy())\n",
        "            total_labels = np.append(total_labels, labels.cpu().numpy())\n",
        "\n",
        "    return losses, predicted_classes, true_classes\n",
        "\n",
        "\n",
        "# частично с помощью https://matplotlib.org/devdocs/gallery/subplots_axes_and_figures/subplots_demo.html\n",
        "def plot_metrics(train, val):\n",
        "    clear_output(True)\n",
        "    fig, axs = plt.subplots(2, figsize=(13, 14))\n",
        "    fig.suptitle('Learning progress')\n",
        "\n",
        "    epoch = len(train[metric_name])\n",
        "    for i, metric_name in enumerate(['loss', 'accuracy']):\n",
        "        train_metric = train[metric_name]\n",
        "        val_metric = val[metric_name]\n",
        "        axs[i].set_title(metric_name)\n",
        "        axs[i].set(xlabel='epoch', ylabel=metric_name)\n",
        "        axs[i].plot(np.arange(1, epoch + 2), train_metric, label='train', color='r')\n",
        "        axs[i].plot(np.arange(1, epoch + 2), val[metric_name], label='validation', color='g')\n",
        "        axs[i].scatter(epoch + 1, train_metric[-1], label='Last {}={:.2f} on train'.format(metric_name, train_metric[-1]))\n",
        "        axs[i].scatter(epoch + 1, val_metric[-1], label='Last {}={:.2f} on validation'.format(metric_name, val_metric[-1]))\n",
        "\n",
        "\n",
        "# Частично мой код из первого домашнего задания\n",
        "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n",
        "    model.to(device)\n",
        "    train_metrics = {\n",
        "        'loss' : [],\n",
        "        'accuracy' : []\n",
        "    }\n",
        "    val_metrics = {\n",
        "        'loss' : [],\n",
        "        'accuracy' : []\n",
        "    }\n",
        "    for epoch in range(n_epochs):\n",
        "        losses, predicted_classes, true_classes = train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
        "        train_metrics['loss'].append(losses.mean())\n",
        "        train_metrics['acc'].append((predicted_classes == true_classes).float().mean())\n",
        "\n",
        "        losses, predicted_classes, true_classes = predict(model, val_dataloader, criterion, device)\n",
        "        val_metrics['loss'].append(losses.mean())\n",
        "        val_metrics['acc'].append((predicted_classes == true_classes).float().mean())\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "        plot_metrics(train_metrics, val_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxR3gfcilRVW"
      },
      "source": [
        "### Обучение модели, запуски экспериментов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 8,
        "scrolled": true,
        "id": "JXFJ6oS8lRVX"
      },
      "source": [
        "model = \n",
        "optimizer = # YOUR OPTIMIZER\n",
        "criterion = # LOSS THAT YOU OPTIMIZE (SHOLD BE CROSS ENTROPY OR SMTH ELSE)\n",
        "scheduler = # LR SCHEDULE THAT YOU PROBABLY CHOOSE\n",
        "n_epochs = # NUMBER OF EPOCHS\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 9,
        "id": "CesoOl6BlRVY"
      },
      "source": [
        "Простой тест на проверку правильности написанного кода"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 10,
        "id": "B_LB2jn6lRVY"
      },
      "source": [
        "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "assert len(predicted_labels) == len(val_dataset)\n",
        "accuracy = accuracy_score(predicted_labels, true_labels)\n",
        "print(\"tests passed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 11,
        "id": "tS-LLiXUlRVY"
      },
      "source": [
        "Запустить обучение можно в ячейке ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 12,
        "id": "ECIzZ_RYlRVZ"
      },
      "source": [
        "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVW8_EXlRVZ"
      },
      "source": [
        "### Проверка полученной accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 13,
        "id": "FmR-elhJlRVZ"
      },
      "source": [
        "После всех экспериментов которые вы проделали, выберите лучшую из своих моделей, реализуйте и запустите функцию `evaluate`. Эта функция должна брать на вход модель и даталоадер с валидационными данными и возврашать accuracy, посчитанную на этом датасете."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 14,
        "id": "3TGH0EFalRVb"
      },
      "source": [
        "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "assert len(predicted_labels) == len(val_dataset)\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(\"Оценка за это задание составит {} баллов\".format(min(5, 5 * accuracy / 0.44)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 15,
        "id": "pT8vfPSolRVb"
      },
      "source": [
        "### Отчёт об экспериментах \n",
        "\n",
        "текст писать тут"
      ]
    }
  ]
}