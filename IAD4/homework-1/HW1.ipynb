{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b22J4hegY1_Y"
      },
      "source": [
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/logo_hse.png?raw=1\" width=\"1000\"></center>\n",
        "\n",
        "<h1><center>Прикладные задачи анализа данных</center></h1>\n",
        "<h2><center>Домашнее задание: генеративно-состязательные сети</center></h2>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hse-ds/iad-applied-ds.git"
      ],
      "metadata": {
        "id": "_h9EddAZZCsF",
        "outputId": "fd832d39-025c-4af1-b07f-78c170ab1190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'iad-applied-ds'...\n",
            "remote: Enumerating objects: 779, done.\u001b[K\n",
            "remote: Counting objects: 100% (295/295), done.\u001b[K\n",
            "remote: Compressing objects: 100% (228/228), done.\u001b[K\n",
            "remote: Total 779 (delta 113), reused 180 (delta 56), pack-reused 484\u001b[K\n",
            "Receiving objects: 100% (779/779), 141.16 MiB | 28.15 MiB/s, done.\n",
            "Resolving deltas: 100% (233/233), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('iad-applied-ds/2022/hw/hw1')"
      ],
      "metadata": {
        "id": "I3at864-ZIp3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCloqUOfY1_a"
      },
      "source": [
        "# Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ-lcMGFY1_b"
      },
      "source": [
        "## MAGIC – Major Atmospheric Gamma Imaging Cherenkov Telescope"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvJbAfo9Y1_b"
      },
      "source": [
        "MAGIC (Major Atmospheric Gamma Imaging Cherenkov) - это система, состоящая из двух черенковских телескопов диаметром 17 м. Они предназначены для наблюдения гамма-лучей от галактических и внегалактических источников в диапазоне очень высоких энергий (от 30 ГэВ до 100 ТэВ). \n",
        "\n",
        "Телескопами MAGIC в настоящее время управляют около 165 астрофизиков из 24 организаций и консорциумов из 12 стран. MAGIC позволил открыть и исследовать новые классы источников гамма-излучения, таких как, например, пульсары и гамма-всплески (GRB).\n",
        "\n",
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/magic1.jpg?raw=1\" width=\"1000\"></center>\n",
        "\n",
        "Источник: https://magic.mpp.mpg.de/\n",
        "\n",
        "Youtube video: https://youtu.be/mjcDSR2vSU8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZhZ3hnSY1_b"
      },
      "source": [
        "## Частицы из космоса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dflag5oxY1_c"
      },
      "source": [
        "Космические частицы, $\\gamma$-кванты (фотоны) и адроны (протоны), взаимодействуют с атмосферой и порождают ливни вторичных частиц. Двигаясь с околосветовой скоростью, эти частицы излучают Черенковское излучение. Телескопы фотографируют это излучение. По фотографиям можно определить тип частицы из космоса: фотон или протон.\n",
        "\n",
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/shower.jpg?raw=1\" width=\"500\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt-v-QnvY1_c"
      },
      "source": [
        "## Фотографии"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8QwBr-UY1_c"
      },
      "source": [
        "Задача атмосферного черенковского телескопа - получить изображение ливня путем измерения черенковского света от частиц ливня. Это изображение представляет собой геометрическую проекцию ливня на детектор. Для анализа этих изображений были введены параметры изображения или так называемые параметры Хилласа. Есть два вида параметров изображения: параметры формы и параметры ориентации. (Источник: http://ihp-lx.ethz.ch/Stamet/magic/parameters.html)\n",
        "\n",
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/geo.jpg?raw=1\" width=\"400\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "657zHnW7Y1_c"
      },
      "source": [
        "## Фотоны vs адронов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHsfO6ODY1_d"
      },
      "source": [
        "Изображения для $\\gamma$-квантов (фотонов) и адронов (протонов) отличаются по форме кластеров. Астрономы используют модели машинного обучения для классификации этих изображений. Для обучения моделей ученые искусственно генерируют такие изображения для каждого типа частиц с помощью сложных физических симуляторов.\n",
        "\n",
        "\n",
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/gamma_p.png?raw=1\" width=\"600\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btpmFB2JY1_e"
      },
      "source": [
        "## Ускорение симуляции"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dj6V75ZY1_e"
      },
      "source": [
        "Сложные физические симуляторы требуют больших вычислительных ресурсов. Они моделируют прилет частиц из космоса, их взаимодействие с атмосферой, рождение ливней, черенковского излучения и работы телескопов для получения изображений. Но мы можем использовать генеративно-состязательные сети для быстрой симуляции!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "13y6DIkEY1_e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXJ2Cz0ZY1_h"
      },
      "source": [
        "# Данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usvGeahyY1_h"
      },
      "source": [
        "Будем использовать данные телескопа MAGIC из UCI репозитория https://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope. Каждый объект в данных - параметры одного изображения кластера и метка этого кластера (фотон или адрон):\n",
        "\n",
        "\n",
        "0. Length: major axis of ellipse [mm]\n",
        "1. Width: minor axis of ellipse [mm]\n",
        "2. Size: 10-log of sum of content of all pixels [in #phot]\n",
        "3. Conc: ratio of sum of two highest pixels over fSize [ratio]\n",
        "4. Conc1: ratio of highest pixel over fSize [ratio]\n",
        "5. Asym: distance from highest pixel to center, projected onto major axis [mm]\n",
        "6. M3Long: 3rd root of third moment along major axis [mm]\n",
        "7. M3Trans: 3rd root of third moment along minor axis [mm]\n",
        "8. Alpha: angle of major axis with vector to origin [deg]\n",
        "9. Dist: distance from origin to center of ellipse [mm]\n",
        "10. class: g,h # gamma (signal), hadron (background)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hDgZzqsSY1_i",
        "outputId": "c524d513-1872-4087-a9a4-62d2a819cd5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-44259f1c-e62c-42f8-8cb1-5ec4cc171445\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Width</th>\n",
              "      <th>Size</th>\n",
              "      <th>Conc</th>\n",
              "      <th>Conc1</th>\n",
              "      <th>Asym</th>\n",
              "      <th>M3Long</th>\n",
              "      <th>M3Trans</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>Dist</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.7967</td>\n",
              "      <td>16.0021</td>\n",
              "      <td>2.6449</td>\n",
              "      <td>0.3918</td>\n",
              "      <td>0.1982</td>\n",
              "      <td>27.7004</td>\n",
              "      <td>22.0110</td>\n",
              "      <td>-8.2027</td>\n",
              "      <td>40.0920</td>\n",
              "      <td>81.8828</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.6036</td>\n",
              "      <td>11.7235</td>\n",
              "      <td>2.5185</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.3773</td>\n",
              "      <td>26.2722</td>\n",
              "      <td>23.8238</td>\n",
              "      <td>-9.9574</td>\n",
              "      <td>6.3609</td>\n",
              "      <td>205.2610</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>162.0520</td>\n",
              "      <td>136.0310</td>\n",
              "      <td>4.0612</td>\n",
              "      <td>0.0374</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>116.7410</td>\n",
              "      <td>-64.8580</td>\n",
              "      <td>-45.2160</td>\n",
              "      <td>76.9600</td>\n",
              "      <td>256.7880</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.8172</td>\n",
              "      <td>9.5728</td>\n",
              "      <td>2.3385</td>\n",
              "      <td>0.6147</td>\n",
              "      <td>0.3922</td>\n",
              "      <td>27.2107</td>\n",
              "      <td>-6.4633</td>\n",
              "      <td>-7.1513</td>\n",
              "      <td>10.4490</td>\n",
              "      <td>116.7370</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75.1362</td>\n",
              "      <td>30.9205</td>\n",
              "      <td>3.1611</td>\n",
              "      <td>0.3168</td>\n",
              "      <td>0.1832</td>\n",
              "      <td>-5.5277</td>\n",
              "      <td>28.5525</td>\n",
              "      <td>21.8393</td>\n",
              "      <td>4.6480</td>\n",
              "      <td>356.4620</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44259f1c-e62c-42f8-8cb1-5ec4cc171445')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44259f1c-e62c-42f8-8cb1-5ec4cc171445 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44259f1c-e62c-42f8-8cb1-5ec4cc171445');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Length     Width    Size    Conc  ...  M3Trans    Alpha      Dist  class\n",
              "0   28.7967   16.0021  2.6449  0.3918  ...  -8.2027  40.0920   81.8828      g\n",
              "1   31.6036   11.7235  2.5185  0.5303  ...  -9.9574   6.3609  205.2610      g\n",
              "2  162.0520  136.0310  4.0612  0.0374  ... -45.2160  76.9600  256.7880      g\n",
              "3   23.8172    9.5728  2.3385  0.6147  ...  -7.1513  10.4490  116.7370      g\n",
              "4   75.1362   30.9205  3.1611  0.3168  ...  21.8393   4.6480  356.4620      g\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# read data\n",
        "names = np.array(['Length', 'Width', 'Size', 'Conc', 'Conc1', 'Asym', 'M3Long', 'M3Trans', 'Alpha', 'Dist', 'class'])\n",
        "data = pd.read_csv(\"data/magic04.data\", header=None)\n",
        "data.columns = names\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PEt8CnqY1_i"
      },
      "source": [
        "# Постановка задачи\n",
        "\n",
        "Ваша задача заключается в том, чтобы с помощью генеративно-состязательных сетей научится генерировать параметры кластеров на изображениях телекопа для каждого типа частиц (фотона или адрона):\n",
        "\n",
        "- $X$ - матрица реальных объектов, которые нужно начиться генерировать;\n",
        "- $y$ - метки классов, которые будем использовать как условие при генерации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5nhabfOY1_i"
      },
      "outputs": [],
      "source": [
        "# параметры кластеров на изображениях\n",
        "X = data[names[:-1]].values\n",
        "X = np.abs(X)\n",
        "\n",
        "# метки классов\n",
        "labels = data[names[-1]].values\n",
        "y = np.ones((len(labels), 1))\n",
        "y[labels == 'h'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RngAxbEYY1_j"
      },
      "outputs": [],
      "source": [
        "# примеры\n",
        "X[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpiroZHVY1_j"
      },
      "outputs": [],
      "source": [
        "# примеры\n",
        "y[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpIeOHsGY1_j"
      },
      "source": [
        "# Визуализация данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e6HOs-xY1_j"
      },
      "source": [
        "Каждое изображение описывается 10 параметрами. Давайте построим распделения значений каждого параметра для каждого типа частиц."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-g-ZTvzY1_j"
      },
      "outputs": [],
      "source": [
        "def plot_hists(X1, X2, names, label1, label2, bins=np.linspace(-3, 3, 61)):\n",
        "    plt.figure(figsize=(4*4, 4*2))\n",
        "    for i in range(X1.shape[1]):\n",
        "        plt.subplot(3, 4, i+1)\n",
        "        plt.hist(X1[:, i], bins=bins, alpha=0.5, label=label1, color='C0')\n",
        "        plt.hist(X2[:, i], bins=bins, alpha=0.5, label=label2, color='C1')\n",
        "        plt.xlabel(names[i], size=14)\n",
        "        plt.legend(loc='best')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oXUClKCY1_k"
      },
      "outputs": [],
      "source": [
        "plot_hists(X[y[:, 0]==0], X[y[:, 0]==1], names, label1=\"Hadrons\", label2=\"Photons\", bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLEVYfzbY1_k"
      },
      "source": [
        "# Предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04jkFgb9Y1_k"
      },
      "source": [
        "Из графика видим, что распределения для многих признаков имеют тяжелые хвосты. Это делает обучение генеративных моделей тяжелее. Поэтому, нужно как-то преобразовать данные, чтобы убрать эти тяжелые хвосты. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vTajLE8Y1_k"
      },
      "source": [
        "## Задание 1 (1 балл)\n",
        "\n",
        "Используя функцию `sklearn.preprocessing.QuantileTransformer` трансформируйте входные данные `X`. Это преобразование делает так, чтобы распределение каждого параметра было нормальным. Описание функции доступно по ссылке http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html. Используйте значение параметра `output_distribution='normal'`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgfZ0qBiY1_k"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE IS HERE ######\n",
        "X_qt = ...\n",
        "### THE END OF YOUR CODE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTTtxFdiY1_l"
      },
      "outputs": [],
      "source": [
        "plot_hists(X_qt[y[:, 0]==0], X_qt[y[:, 0]==1], names, label1=\"Hadrons\", label2=\"Photons\", bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raWSj7AnY1_l"
      },
      "source": [
        "# Обучающая и тестовая выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnx_V97ZY1_l"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train / test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_qt, y, stratify=y, test_size=0.5, shuffle=True, random_state=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM2zOOFtY1_l"
      },
      "outputs": [],
      "source": [
        "plot_hists(X_train, X_test, names, label1=\"Train\", label2=\"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUII6Nn8Y1_l"
      },
      "source": [
        "# Conditional WGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF8STtzIY1_l"
      },
      "source": [
        "Мы будем использовать `Conditional WGAN`, который изображен на рисунке. В качестве условия `y` мы будем использовать метку класса: **0** - адрон, **1** - фотон. Таким образом, мы будем сообщать генератору для какой частицы нужно генерировать параметры изображения. \n",
        "\n",
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/cgan.png?raw=1\" width=\"800\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZFNPQ6HY1_l"
      },
      "source": [
        "Генератор $\\hat{x} = G(z, y)$ будет принимать на вход шумовой вектор $z$ и вектор условий $y$, а выдавать будет сгенерированный (фейковый) вектор параметров $\\hat{x}$. \n",
        "\n",
        "Дискриминатор $D(x, y)$ будет принимать на вход вектор параметров $x$ и вектор условий $y$, а возвращать будет рациональное число.\n",
        "\n",
        "Обучать `Conditional WGAN` будем с такой функцией потерь:\n",
        "\n",
        "$$L(G, D) = -\\frac{1}{n} \\sum_{x_i \\in X, y_i \\in y} D(x_i, y_i) + -\\frac{1}{n} \\sum_{z_i \\in Z, y_i \\in y} D(G(z_i, y_i), y_i) \\to \\max_G \\min_D$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFN9sI6eY1_m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgL2ME9uY1_m"
      },
      "outputs": [],
      "source": [
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z45g-iV_Y1_m"
      },
      "source": [
        "## Задание 2 (1 балл)\n",
        "\n",
        "Реализуйте нейронную сеть для генератора со следующими слоями:\n",
        "- Полносвязный слой со 100 нейронами;\n",
        "- Слой батч-нормализации;\n",
        "- ReLU функцию активации;\n",
        "- Полносвязный слой со 100 нейронами;\n",
        "- Слой батч-нормализации;\n",
        "- ReLU функцию активации;\n",
        "- Выходной слой.\n",
        "\n",
        "Подсказка: используйте функцию `nn.Sequential()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmhUHVh5Y1_m"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_inputs, n_outputs):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        ### YOUR CODE IS HERE ######\n",
        "        self.net = ...\n",
        "        ### THE END OF YOUR CODE ###\n",
        "\n",
        "    def forward(self, z, y):\n",
        "        zy = torch.cat((z, y), dim=1)\n",
        "        return self.net(zy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBtDJZvaY1_m"
      },
      "source": [
        "## Задание 3 (1 балл)\n",
        "\n",
        "Реализуйте нейронную сеть для дискриминатора со следующими слоями:\n",
        "- Полносвязный слой со 100 нейронами;\n",
        "- ReLU функцию активации;\n",
        "- Полносвязный слой со 100 нейронами;\n",
        "- ReLU функцию активации;\n",
        "- Выходной слой.\n",
        "\n",
        "Подсказка: используйте функцию `nn.Sequential()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rjfgk1MY1_n"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_inputs):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        ### YOUR CODE IS HERE ######\n",
        "        self.net = ...\n",
        "        ### THE END OF YOUR CODE ###\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        xy = torch.cat((x, y), dim=1)\n",
        "        return self.net(xy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWpD5jhrY1_n"
      },
      "source": [
        "## Задание 4 (2 балла)\n",
        "\n",
        "Реализуйте класс для обучения генеративной модели.\n",
        "\n",
        "- Подсказка 1: не забывайте ограничивать веса дискриминатора. Для этого используйте `p.data.clamp_(-0.01, 0.01)`, где `p` веса дискриминатора.\n",
        "- Подсказка 2: `n_critic` - число итераций обучения дискриминатора на одну итерацию обучения генератора.\n",
        "- Подсказка 3: Используйте `X_tensor = torch.tensor(X_numpy, dtype=torch.float, device=DEVICE)` для перевода numpy в тензор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaaizlggY1_n"
      },
      "outputs": [],
      "source": [
        "class Fitter(object):\n",
        "    \n",
        "    def __init__(self, generator, discriminator, batch_size=32, n_epochs=10, latent_dim=1, lr=0.0001, n_critic=5):\n",
        "        \n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.batch_size = batch_size\n",
        "        self.n_epochs = n_epochs\n",
        "        self.latent_dim = latent_dim\n",
        "        self.lr = lr\n",
        "        self.n_critic = n_critic\n",
        "        \n",
        "        self.opt_gen  = torch.optim.RMSprop(self.generator.parameters(), lr=self.lr)\n",
        "        self.opt_disc = torch.optim.RMSprop(self.discriminator.parameters(), lr=self.lr)\n",
        "        \n",
        "        self.generator.to(DEVICE)\n",
        "        self.discriminator.to(DEVICE)\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        # numpy to tensor\n",
        "        X_real = torch.tensor(X, dtype=torch.float, device=DEVICE)\n",
        "        y_cond = torch.tensor(y, dtype=torch.float, device=DEVICE)\n",
        "        \n",
        "        # tensor to dataset\n",
        "        dataset_real = TensorDataset(X_real, y_cond)\n",
        "        \n",
        "        # Turn on training\n",
        "        self.generator.train(True)\n",
        "        self.discriminator.train(True)\n",
        "        \n",
        "        self.loss_history = []\n",
        "\n",
        "        # Fit GAN\n",
        "        for epoch in range(self.n_epochs):\n",
        "            for i, (real_batch, cond_batch) in enumerate(DataLoader(dataset_real, batch_size=self.batch_size, shuffle=True)):\n",
        "                \n",
        "                ### YOUR CODE IS HERE ######\n",
        "                \n",
        "                ...\n",
        "                    \n",
        "                ### THE END OF YOUR CODE ###\n",
        "                    \n",
        "            # caiculate and store loss after an epoch\n",
        "            Z_noise = torch.normal(0, 1, (len(X_real), self.latent_dim))\n",
        "            X_fake = self.generator(Z_noise, y_cond)\n",
        "            loss_epoch = torch.mean(self.discriminator(X_real, y_cond)) - torch.mean(self.discriminator(X_fake, y_cond))\n",
        "            self.loss_history.append(loss_epoch.detach().cpu())\n",
        "                    \n",
        "        # Turn off training\n",
        "        self.generator.train(False)\n",
        "        self.discriminator.train(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DWSmkxNY1_n"
      },
      "source": [
        "## Обучение\n",
        "Обучим модель на данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqK5yjL-Y1_n"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "latent_dim = 10\n",
        "generator     = Generator(n_inputs=latent_dim+y.shape[1], \n",
        "                          n_outputs=X_train.shape[1])\n",
        "discriminator = Discriminator(n_inputs=X_train.shape[1]+y.shape[1])\n",
        "\n",
        "fitter = Fitter(generator, discriminator, batch_size=50, n_epochs=100, latent_dim=latent_dim, lr=0.0001, n_critic=5)\n",
        "fitter.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do28hA5-Y1_o"
      },
      "outputs": [],
      "source": [
        "# WGAN learning curve\n",
        "plt.figure(figsize=(9, 5))\n",
        "plt.plot(fitter.loss_history)\n",
        "plt.xlabel(\"Epoch Number\", size=14)\n",
        "plt.ylabel(\"Loss Function\", size=14)\n",
        "plt.xticks(size=14)\n",
        "plt.yticks(size=14)\n",
        "plt.title(\"Conditional WGAN Learning Curve\", size=14)\n",
        "plt.grid(b=1, linestyle='--', linewidth=0.5, color='0.5')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTXUvPanY1_o"
      },
      "source": [
        "## Задание 5 (1 балл)\n",
        "\n",
        "Реализуйте функцию для генерации новый объектов $X$ по вектору условий $y$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZAbLdx7Y1_o"
      },
      "outputs": [],
      "source": [
        "def generate(generator, y, latent_dim):\n",
        "    ### YOUR CODE IS HERE ######\n",
        "    X_fake = ...\n",
        "    ### THE END OF YOUR CODE ###\n",
        "    return X_fake # numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96XGGbfvY1_o"
      },
      "source": [
        "Теперь сгенерируем фейковые матрицы `X_fake_train` и `X_fake_test`. Сравним их с матрицами реальных объектов `X_train` и `X_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k90ZuFlAY1_o"
      },
      "outputs": [],
      "source": [
        "X_fake_train = generate(fitter.generator, y_train, latent_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl0fZmABY1_o"
      },
      "outputs": [],
      "source": [
        "plot_hists(X_train, X_fake_train, names, label1=\"Real\", label2=\"Fake\", bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-KGRueGY1_o"
      },
      "outputs": [],
      "source": [
        "X_fake_test = generate(fitter.generator, y_test, latent_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0n8KK4mY1_o"
      },
      "outputs": [],
      "source": [
        "plot_hists(X_test, X_fake_test, names, label1=\"Real\", label2=\"Fake\", bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd7iVQYiY1_p"
      },
      "source": [
        "## Вывод 1: \n",
        "Визуально мы видим сходство реальных и фейковых данных. Однако это только проекции 10-мерных объектов на одну ось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzqUIA3DY1_p"
      },
      "source": [
        "# Измерение качества генерации\n",
        "\n",
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/clf.png?raw=1\" width=\"600\"></center>\n",
        "\n",
        "Измерим сходство распределений классификатором."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6lMT-1TY1_p"
      },
      "outputs": [],
      "source": [
        "# собираем реальный и фейковые матрицы в одну\n",
        "XX_train = np.concatenate((X_fake_train, X_train), axis=0)\n",
        "XX_test = np.concatenate((X_fake_test, X_test), axis=0)\n",
        "\n",
        "yy_train = np.array([0]*len(X_fake_train) + [1]*len(X_train))\n",
        "yy_test = np.array([0]*len(X_fake_test) + [1]*len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7uYEEhCY1_p"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# обучаем классификатор\n",
        "clf = GradientBoostingClassifier()\n",
        "clf.fit(XX_train, yy_train)\n",
        "\n",
        "# получаем прогнозы\n",
        "yy_test_proba = clf.predict_proba(XX_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA6lctitY1_p"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "auc = roc_auc_score(yy_test, yy_test_proba)\n",
        "print(\"ROC AUC = \", auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFZjHGCOY1_q"
      },
      "source": [
        "## Вывод 2\n",
        "\n",
        "Идеальное значение ROC AUC равно 0.5. Это соответствует случаю, когда классификатор не может разделить реальные и фейковые данные. В нашем случае ROC AUC около 0.7, что говорит о том, что есть куда улучшать качество генеративной модели :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugAgZ0JuY1_q"
      },
      "source": [
        "# Условные вариационные автокодировщики"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdxE7nL7Y1_q"
      },
      "source": [
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/cvae.svg?raw=1\" width=\"600\"></center>\n",
        "\n",
        "Теперь, решим эту же задачу используя условный автокодировщик (CVAE). Пользуясь вашим семинаром по теме вариационных автокодировщиков выполните следующие задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkStz3JvY1_s"
      },
      "source": [
        "## Задание 6 (1 балл)\n",
        "\n",
        "Реализуйте нейронную сеть для декодеровщика со следующими слоями:\n",
        "- Полносвязный слой со 100 нейронами;\n",
        "- Слой батч-нормализации;\n",
        "- ReLU функцию активации;\n",
        "- Полносвязный слой со 100 нейронами;\n",
        "- Слой батч-нормализации;\n",
        "- ReLU функцию активации;\n",
        "- Выходной слой для mu; Выходной слой для log_sigma;\n",
        "\n",
        "Подсказка: используйте функцию `nn.Sequential()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4U2N_KnY1_s"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_inputs, lat_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        ### YOUR CODE IS HERE ######\n",
        "        self.enc_net = ...\n",
        "        \n",
        "        self.mu = ...\n",
        "        self.log_sigma = ...\n",
        "        ### THE END OF YOUR CODE ###\n",
        "        \n",
        "    def forward(self, x, y):\n",
        "        z = torch.cat((x, y), dim=1)\n",
        "        z = self.enc_net(z)\n",
        "        mu = self.mu(z)\n",
        "        log_sigma = self.log_sigma(z)\n",
        "        return mu, log_sigma "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjcSJ8U5Y1_s"
      },
      "source": [
        "## Задание 7 (1 балл)\n",
        "\n",
        "Реализуйте нейронную сеть для декодеровщика со следующими слоями:\n",
        "- Полносвязный слой со 100 нейронами;\n",
        "- ReLU функцию активации;\n",
        "- Полносвязный слой со 100 нейронами;\n",
        "- ReLU функцию активации;\n",
        "- Выходной слой.\n",
        "\n",
        "Подсказка: используйте функцию `nn.Sequential()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc5hsBzkY1_t"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        ### YOUR CODE IS HERE ######\n",
        "        self.dec_net = ...\n",
        "        ### THE END OF YOUR CODE ###\n",
        "        \n",
        "    def forward(self, z, y):\n",
        "        z_cond = torch.cat((z, y), dim=1)\n",
        "        x_rec = self.dec_net(z_cond)\n",
        "        return x_rec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMX-QhKSY1_t"
      },
      "source": [
        "## Задание 8 (1 балл)\n",
        "\n",
        "Реализуйте класс для обучения вариационного автокодировщика.\n",
        "\n",
        "Подсказка: Используйте `X_tensor = torch.tensor(X_numpy, dtype=torch.float, device=DEVICE)` для перевода numpy в тензор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY6BLWAOY1_t"
      },
      "outputs": [],
      "source": [
        "class VAEFitter(object):\n",
        "    \n",
        "    def __init__(self, encoder, decoder, batch_size=32, n_epochs=10, latent_dim=1, lr=0.0001, KL_weight=0.001):\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.batch_size = batch_size\n",
        "        self.n_epochs = n_epochs\n",
        "        self.latent_dim = latent_dim\n",
        "        self.lr = lr\n",
        "        self.KL_weight = KL_weight\n",
        "        \n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.opt  = torch.optim.RMSprop(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=self.lr)\n",
        "        \n",
        "        self.encoder.to(DEVICE)\n",
        "        self.decoder.to(DEVICE)\n",
        "        \n",
        "        \n",
        "    def sample_z(self, mu, log_sigma):\n",
        "        eps = torch.randn(mu.shape).to(DEVICE)\n",
        "        return mu + torch.exp(log_sigma / 2) * eps\n",
        "    \n",
        "    def custom_loss(self, x, rec_x, mu, log_sigma):\n",
        "        KL = torch.mean(-0.5 * torch.sum(1 + log_sigma - mu ** 2 - log_sigma.exp(), dim = 1), dim = 0)\n",
        "        recon_loss = self.criterion(x, rec_x)\n",
        "        return KL*self.KL_weight + recon_loss\n",
        "    \n",
        "    \n",
        "    def compute_loss(self, x_batch, cond_batch):\n",
        "        \n",
        "        ### YOUR CODE IS HERE ######\n",
        "        loss = ...\n",
        "        ### THE END OF YOUR CODE ###\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        # numpy to tensor\n",
        "        X_real = torch.tensor(X, dtype=torch.float, device=DEVICE)\n",
        "        y_cond = torch.tensor(y, dtype=torch.float, device=DEVICE)\n",
        "        \n",
        "        # tensor to dataset\n",
        "        dataset_real = TensorDataset(X_real, y_cond)\n",
        "        \n",
        "        # Turn on training\n",
        "        self.encoder.train(True)\n",
        "        self.decoder.train(True)\n",
        "        \n",
        "        self.loss_history = []\n",
        "\n",
        "        # Fit GAN\n",
        "        for epoch in range(self.n_epochs):\n",
        "            for i, (x_batch, cond_batch) in enumerate(DataLoader(dataset_real, batch_size=self.batch_size, shuffle=True)):\n",
        "                \n",
        "                # caiculate loss\n",
        "                loss = self.compute_loss(x_batch, cond_batch)\n",
        "                \n",
        "                # optimization step\n",
        "                self.opt.zero_grad()\n",
        "                loss.backward()\n",
        "                self.opt.step()\n",
        "                    \n",
        "            # caiculate and store loss after an epoch\n",
        "            loss_epoch = self.compute_loss(X_real, y_cond)\n",
        "            self.loss_history.append(loss_epoch.detach().cpu())\n",
        "                    \n",
        "        # Turn off training\n",
        "        self.encoder.train(False)\n",
        "        self.decoder.train(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBPZRMocY1_t"
      },
      "source": [
        "## Обучение\n",
        "Обучим модель на данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsPT2ZUuY1_t"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "latent_dim = 10\n",
        "\n",
        "encoder = Encoder(n_inputs=X_train.shape[1]+y.shape[1], lat_size=latent_dim)\n",
        "decoder = Decoder(n_inputs=latent_dim+y.shape[1], n_outputs=X_train.shape[1])\n",
        "\n",
        "vae_fitter = VAEFitter(encoder, decoder, batch_size=50, n_epochs=100, latent_dim=latent_dim, lr=0.001, KL_weight=0.001)\n",
        "vae_fitter.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8diWa-CY1_t"
      },
      "outputs": [],
      "source": [
        "# WGAN learning curve\n",
        "plt.figure(figsize=(9, 5))\n",
        "plt.plot(vae_fitter.loss_history)\n",
        "plt.xlabel(\"Epoch Number\", size=14)\n",
        "plt.ylabel(\"Loss Function\", size=14)\n",
        "plt.xticks(size=14)\n",
        "plt.yticks(size=14)\n",
        "plt.title(\"Conditional VAE Learning Curve\", size=14)\n",
        "plt.grid(b=1, linestyle='--', linewidth=0.5, color='0.5')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXvvu17MY1_t"
      },
      "source": [
        "## Задание 9 (1 балл)\n",
        "\n",
        "Реализуйте функцию для генерации новый объектов $X$ по вектору условий $y$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Dc9cb20Y1_t"
      },
      "outputs": [],
      "source": [
        "def generate(decoder, y, latent_dim):\n",
        "    ### YOUR CODE IS HERE ######\n",
        "    X_fake = ...\n",
        "    ### THE END OF YOUR CODE ###\n",
        "    return X_fake # numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P71YHkhIY1_u"
      },
      "source": [
        "Теперь сгенерируем фейковые матрицы `X_fake_train` и `X_fake_test`. Сравним их с матрицами реальных объектов `X_train` и `X_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GQBWiG0Y1_u"
      },
      "outputs": [],
      "source": [
        "X_fake_train = generate(vae_fitter.decoder, y_train, latent_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeuJ0GuDY1_u"
      },
      "outputs": [],
      "source": [
        "plot_hists(X_train, X_fake_train, names, label1=\"Real\", label2=\"Fake\", bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM8frmSsY1_u"
      },
      "outputs": [],
      "source": [
        "X_fake_test = generate(vae_fitter.decoder, y_test, latent_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RUAvSWgY1_u"
      },
      "outputs": [],
      "source": [
        "plot_hists(X_test, X_fake_test, names, label1=\"Real\", label2=\"Fake\", bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DUXGElCY1_u"
      },
      "source": [
        "# Измерение качества генерации\n",
        "\n",
        "Измерим сходство распределений классификатором."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cE1e573MY1_u"
      },
      "outputs": [],
      "source": [
        "# собираем реальный и фейковые матрицы в одну\n",
        "XX_train = np.concatenate((X_fake_train, X_train), axis=0)\n",
        "XX_test = np.concatenate((X_fake_test, X_test), axis=0)\n",
        "\n",
        "yy_train = np.array([0]*len(X_fake_train) + [1]*len(X_train))\n",
        "yy_test = np.array([0]*len(X_fake_test) + [1]*len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnIxSDSGY1_u"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# обучаем классификатор\n",
        "clf = GradientBoostingClassifier()\n",
        "clf.fit(XX_train, yy_train)\n",
        "\n",
        "# получаем прогнозы\n",
        "yy_test_proba = clf.predict_proba(XX_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu5cARB8Y1_v"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "auc = roc_auc_score(yy_test, yy_test_proba)\n",
        "print(\"ROC AUC = \", auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06TIFzPEY1_v"
      },
      "source": [
        "## Вывод 3\n",
        "\n",
        "Для CVAE получили ROC AUC около 0.7 (меньше лучше). Таким образом видим, что в данной задаче обе модели ведут себя схожим образом. Но может их можно как-то улучшить? Или есть какая-то еще модель? :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48WGfgsFY1_v"
      },
      "source": [
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/mem1.jpg?raw=1\" width=\"500\"></center>\n",
        "\n",
        "<center><img src=\"https://github.com/alyonabelenko/Courses/blob/master/IAD4/homework-1/img/mem2.jpg?raw=1\" width=\"500\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1kb_BO2Y1_w"
      },
      "source": [
        "# Бонус (0 баллов)\n",
        "\n",
        "Попробуйте настроить параметры обучения каждой модели или еще как-нибудь их улучшить, чтобы получить как можно меньший ROC AUC. Что получилось? Какая модель лучше? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt5PDf7WY1_w"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "HW1.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}